# Домашнее задание к занятию 6. «Troubleshooting»

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD-операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести эту операцию:

- напишите список операций, которые вы будете производить для остановки запроса пользователя;
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB.


Ответ:
Поднял в докере монгу 
Для поиска проблемных запросов буду использовать команду op

```sh
db.currentOp(
   {
     "active" : true,
     "secs_running" : { "$gt" : 180 },
   }
)
```

В моей тестовой монге таких нет , поэтому промоделировал сделал 2 секунду вот так получилось (внимаине это не ответ это просто демонстрация)

```sh
est> db.currentOp( { "active": true, "secs_running": { "$gt": 2 } } )
{
  inprog: [
    {
      type: 'op',
      host: 'a99e0757de00:27017',
      desc: 'conn1',
      connectionId: 1,
      client: '127.0.0.1:51364',
      appName: 'mongosh 1.10.6',
      clientMetadata: {
        application: { name: 'mongosh 1.10.6' },
        driver: { name: 'nodejs|mongosh', version: '5.7.0|1.10.6' },
        platform: 'Node.js v16.20.2, LE',
        os: {
          name: 'linux',
          architecture: 'arm64',
          version: '5.15.49-linuxkit-pr',
          type: 'Linux'
        }
      },
      active: true,
      currentOpTime: '2023-09-04T13:49:57.027+00:00',
      threaded: true,
      opid: 5269,
      secs_running: Long("7"),
      microsecs_running: Long("7836284"),
      op: 'command',
      ns: 'admin.$cmd',
      redacted: false,
      command: {
        hello: 1,
        maxAwaitTimeMS: 10000,
        topologyVersion: {
          processId: ObjectId("64f5ded01d655233b44ee08b"),
          counter: Long("0")
        },
        '$db': 'admin'
      },
      numYields: 0,
      locks: {},
      waitingForLock: false,
      lockStats: {},
      waitingForFlowControl: false,
      flowControlStats: {}
    }
  ],
  ok: 1
}
```

Зная opid операции можно её прибить, командой:
```sh
db.killOp(<opid>)
```

Пример:
```sh
test> db.killOp(5269)
{ info: 'attempting to kill op', ok: 1 }
```



Хорошим тоном разработчики должны вводить таймауты на свои операции и использовать вот этот метод:

https://www.mongodb.com/docs/manual/tutorial/terminate-running-operations/#maxtimems

Метод maxTimeMS() устанавливает ограничение по времени для операции. Когда операция достигает указанного срока, MongoDB прерывает операцию.

Кроме этого в монго есть профайлер который позволяет отслеживать любые запросы по различным критериям работы

https://www.mongodb.com/docs/manual/tutorial/manage-the-database-profiler/



## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причём отношение количества записанных key-value-значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:

- сначала происходит рост отношения записанных значений к истекшим,
- Redis блокирует операции записи.

Как вы думаете, в чём может быть проблема?
 
Ответ:
Проблема может быть связана с увеличением количества записей с истекшим ttl, которые Redis должен удалить, но по какой-то причине у него не хватает ресурсов или времени для обработки всех этих удалений.  Может здесь проблема реплик и проблема/задержка с сетью. В итоге все это вызывает блокировку операций записи, так как Redis должен сначала очистить устаревшие данные, прежде чем записать новые. 


## Задача 3

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей в таблицах базы
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения этой проблемы вы можете предложить?


Ответ:

Ошибка "lost connection to mysql server during query" может происходить по нескольким причинам:

1. Превышение лимитов на количество одновременных соединений с базой данных. Следует проверить  настройки MySQL и убедится, что ограничение на количество соединений установлено на достаточно высокий уровень для обработки большого количества запросов. 

2. Использование большого объема данных или сложных запросов, приводящих к длительной обработке на стороне сервера MySQL. В таком случае, надо проверить, есть ли индексы на таблицах, используется ли оптимизатор запросов.

3. Проблемы со стабильностью сети или другими факторами, которые приводят к разрыву соединения с базой данных. Надо проверить журналы сети и настройки соединения MySQL, при необходимости установить таймауты соединения

Первое чтобы я сделал - Надо посмотреть еще какие то ошибки в логах есть или нет , но наверное поднял бы количество одновременных соединений (обсудив с разрабами) , при необходимости рассмотрел бы вариант кэширования запросов и балансировки запросов (не знаю насколько в mysql развиты данные способы), 
Второе, или одновременно с этим, закинул бы задачу DBA пусть смотрит )))
Пусть смотрит индексы , и планы запросов


## Задача 4


Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объёмом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили эту проблему?

Ответ:

Сообщение "postmaster invoked oom-killer" указывает на то, что процесс postmaster (управляющий процесс базы данных) выбран процессом для уничтожения (kill) oom-killer из-за нехватки памяти в системе. 

Чтобы решить эту проблему, можно предпринять следующие шаги:

Определить причину нехватки памяти: 
Смотреть логи syslog, kern.log проверить есть ли что то еще что жрет память , например JVM и какой нибудь эластик стоит рядом . Также посмотрел бы какие настройки по памяти у самого постреса

Устранить:
Если памяти не хватает действительно то добавить либо физически на сервер , либо если это виртуалка, дать виртуалке эти ресурсы

Совместно бы с разработчиками изучал бы может есть какие то жесткие запросы сложные, так как речь идет про гис и большие объемы данных

